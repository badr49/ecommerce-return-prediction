{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Mod√©lisation Simple (Baseline Avanc√©)\n",
    "\n",
    "## üéØ Objectif\n",
    "Cr√©er des mod√®les baseline simples mais avec toutes les techniques avanc√©es demand√©es :\n",
    "- **PolynomialFeatures** : G√©n√©ration de features non-lin√©aires (degr√© 1-2)\n",
    "- **SequentialFeatureSelector** : S√©lection automatique des meilleures features\n",
    "- **CrossValidation** : StratifiedKFold pour validation robuste\n",
    "- **GridSearchCV** : Optimisation des hyperparam√®tres sur les pipelines\n",
    "- **Pipeline** : Le pipeline DEVIENT le mod√®le (am√©lior√© par GridSearchCV)\n",
    "\n",
    "## üìä Comparaison\n",
    "- **KNN vs R√©gression Lin√©aire vs R√©gression Logistique**\n",
    "- **Sauvegarder chaque mod√®le** pour comparaison dans Streamlit\n",
    "- **Respecter le cahier des charges** du projet\n",
    "\n",
    "## üîß Approche\n",
    "1. **Baseline Simple** : Features de base (Quantity, UnitPrice, Discount, ShippingCost)\n",
    "2. **Techniques Avanc√©es** : Appliquer toutes les techniques demand√©es\n",
    "3. **Pipeline = Mod√®le** : Le pipeline optimis√© devient le mod√®le final\n",
    "4. **Comparaison** : 3 algorithmes avec m√™mes techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports pour baseline simple avec techniques avanc√©es\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Techniques avanc√©es\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, \n",
    "                           roc_auc_score, mean_squared_error)\n",
    "\n",
    "# Mod√®les baseline simples (3 algorithmes requis)\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es pr√©trait√©es charg√©es depuis le notebook de pr√©traitement\n",
      "üèãÔ∏è Entra√Ænement : (34847, 41)\n",
      "üß™ Test : (7468, 41)\n",
      "üìä Taux retour - Train : 0.098\n",
      "üìä Taux retour - Test : 0.098\n",
      "üîß Features utilis√©es : 41\n",
      "üìã Features : ['cat__Country_Belgium', 'cat__Country_France', 'cat__Country_Germany', 'cat__Country_Italy', 'cat__Country_Netherlands', 'cat__Country_Norway', 'cat__Country_Portugal', 'cat__Country_Spain', 'cat__Country_Sweden', 'cat__Country_United Kingdom', 'cat__Country_United States', 'cat__PaymentMethod_Credit Card', 'cat__PaymentMethod_paypall', 'cat__Category_Apparel', 'cat__Category_Electronics', 'cat__Category_Furniture', 'cat__Category_Stationery', 'cat__SalesChannel_Online', 'cat__ShipmentProvider_FedEx', 'cat__ShipmentProvider_Royal Mail', 'cat__ShipmentProvider_UPS', 'cat__WarehouseLocation_Berlin', 'cat__WarehouseLocation_London', 'cat__WarehouseLocation_Paris', 'cat__WarehouseLocation_Rome', 'cat__WarehouseLocation_Unknown', 'cat__OrderPriority_Low', 'cat__OrderPriority_Medium', 'num__Quantity', 'num__UnitPrice', 'num__Discount', 'num__ShippingCost', 'num__Weekend', 'num__IsMonthEnd', 'num__IsMonthStart', 'num__TotalPrice', 'num__DiscountRate', 'num__ShippingRatio', 'num__CategoryAvgPrice', 'num__CategoryStdPrice', 'num__PriceVsCategoryAvg']\n",
      "‚úÖ available_features d√©fini : ['cat__Country_Belgium', 'cat__Country_France', 'cat__Country_Germany', 'cat__Country_Italy', 'cat__Country_Netherlands', 'cat__Country_Norway', 'cat__Country_Portugal', 'cat__Country_Spain', 'cat__Country_Sweden', 'cat__Country_United Kingdom', 'cat__Country_United States', 'cat__PaymentMethod_Credit Card', 'cat__PaymentMethod_paypall', 'cat__Category_Apparel', 'cat__Category_Electronics', 'cat__Category_Furniture', 'cat__Category_Stationery', 'cat__SalesChannel_Online', 'cat__ShipmentProvider_FedEx', 'cat__ShipmentProvider_Royal Mail', 'cat__ShipmentProvider_UPS', 'cat__WarehouseLocation_Berlin', 'cat__WarehouseLocation_London', 'cat__WarehouseLocation_Paris', 'cat__WarehouseLocation_Rome', 'cat__WarehouseLocation_Unknown', 'cat__OrderPriority_Low', 'cat__OrderPriority_Medium', 'num__Quantity', 'num__UnitPrice', 'num__Discount', 'num__ShippingCost', 'num__Weekend', 'num__IsMonthEnd', 'num__IsMonthStart', 'num__TotalPrice', 'num__DiscountRate', 'num__ShippingRatio', 'num__CategoryAvgPrice', 'num__CategoryStdPrice', 'num__PriceVsCategoryAvg']\n"
     ]
    }
   ],
   "source": [
    "# Chargement des donn√©es pr√©trait√©es\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger les donn√©es pr√©trait√©es depuis le notebook de pr√©traitement\n",
    "preprocessed_data = joblib.load('../data/processed/preprocessed_data.pkl')\n",
    "\n",
    "# Extraire les donn√©es\n",
    "X_train = preprocessed_data['X_train']\n",
    "X_test = preprocessed_data['X_test']\n",
    "y_train = preprocessed_data['y_train']\n",
    "y_test = preprocessed_data['y_test']\n",
    "\n",
    "# R√©cup√©rer les informations du pr√©traitement\n",
    "preprocessor = preprocessed_data['pipeline']\n",
    "feature_names = preprocessed_data['feature_names']\n",
    "\n",
    "print(\"‚úÖ Donn√©es pr√©trait√©es charg√©es depuis le notebook de pr√©traitement\")\n",
    "print(f\"üèãÔ∏è Entra√Ænement : {X_train.shape}\")\n",
    "print(f\"üß™ Test : {X_test.shape}\")\n",
    "print(f\"üìä Taux retour - Train : {y_train.mean():.3f}\")\n",
    "print(f\"üìä Taux retour - Test : {y_test.mean():.3f}\")\n",
    "print(f\"üîß Features utilis√©es : {len(feature_names)}\")\n",
    "print(f\"üìã Features : {feature_names}\")\n",
    "\n",
    "# D√©finir les features pour la sauvegarde (coh√©rent avec le pr√©traitement)\n",
    "available_features = feature_names.copy()\n",
    "print(f\"‚úÖ available_features d√©fini : {available_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ 1. PIPELINE KNN BASELINE AVEC TECHNIQUES AVANC√âES\n",
      "üîç Recherche des meilleurs hyperparam√®tres...\n"
     ]
    }
   ],
   "source": [
    "# 1. PIPELINE KNN BASELINE AVEC TECHNIQUES AVANC√âES\n",
    "print(\"üéØ 1. PIPELINE KNN BASELINE AVEC TECHNIQUES AVANC√âES\")\n",
    "\n",
    "# Pipeline complet = MOD√àLE (am√©lior√© par GridSearchCV)\n",
    "# Note: Les donn√©es sont d√©j√† pr√©trait√©es (standardis√©es et encod√©es)\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),                    # Standardisation\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Features non-lin√©aires\n",
    "    ('feature_selector', SequentialFeatureSelector(   # S√©lection automatique\n",
    "        KNeighborsClassifier(),\n",
    "        n_features_to_select='auto',\n",
    "        direction='forward',\n",
    "        scoring='accuracy',\n",
    "        cv=3\n",
    "    )),\n",
    "    ('knn', KNeighborsClassifier())                  # Mod√®le KNN baseline\n",
    "])\n",
    "\n",
    "# GridSearchCV pour optimiser le pipeline\n",
    "param_grid_knn = {\n",
    "    'poly__degree': [1, 2],\n",
    "    'feature_selector__n_features_to_select': [2, 3, 4],\n",
    "    'knn__n_neighbors': [5, 7, 9],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid_search_knn = GridSearchCV(\n",
    "    knn_pipeline,\n",
    "    param_grid_knn,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"üîç Recherche des meilleurs hyperparam√®tres...\")\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "print(f\"üèÜ Meilleurs param√®tres KNN :\")\n",
    "for param, value in grid_search_knn.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"üìä Meilleur score CV : {grid_search_knn.best_score_:.4f}\")\n",
    "\n",
    "# Le pipeline optimis√© DEVIENT le mod√®le final\n",
    "knn_model_final = grid_search_knn.best_estimator_\n",
    "print(f\"‚úÖ Pipeline KNN optimis√© = Mod√®le final : {type(knn_model_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. PIPELINE R√âGRESSION LIN√âAIRE BASELINE AVEC TECHNIQUES AVANC√âES\n",
    "print(\"üéØ 2. PIPELINE R√âGRESSION LIN√âAIRE BASELINE AVEC TECHNIQUES AVANC√âES\")\n",
    "\n",
    "# Pipeline complet = MOD√àLE (am√©lior√© par GridSearchCV)\n",
    "# Note: Les donn√©es sont d√©j√† pr√©trait√©es (standardis√©es et encod√©es)\n",
    "linreg_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),                    # Standardisation\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Features non-lin√©aires\n",
    "    ('feature_selector', SequentialFeatureSelector(   # S√©lection automatique\n",
    "        LinearRegression(),\n",
    "        n_features_to_select='auto',\n",
    "        direction='forward',\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=3\n",
    "    )),\n",
    "    ('linreg', LinearRegression())                # Mod√®le R√©gression Lin√©aire baseline\n",
    "])\n",
    "\n",
    "# GridSearchCV pour optimiser le pipeline\n",
    "param_grid_linreg = {\n",
    "    'poly__degree': [1, 2],\n",
    "    'feature_selector__n_features_to_select': [2, 3, 4],\n",
    "    'linreg__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "grid_search_linreg = GridSearchCV(\n",
    "    linreg_pipeline,\n",
    "    param_grid_linreg,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"üîç Recherche des meilleurs hyperparam√®tres...\")\n",
    "grid_search_linreg.fit(X_train, y_train)\n",
    "\n",
    "print(f\"üèÜ Meilleurs param√®tres R√©gression Lin√©aire :\")\n",
    "for param, value in grid_search_linreg.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"üìä Meilleur score CV (MSE n√©gatif) : {grid_search_linreg.best_score_:.4f}\")\n",
    "\n",
    "# Le pipeline optimis√© DEVIENT le mod√®le final\n",
    "linreg_model_final = grid_search_linreg.best_estimator_\n",
    "print(f\"‚úÖ Pipeline R√©gression Lin√©aire optimis√© = Mod√®le final : {type(linreg_model_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. PIPELINE R√âGRESSION LOGISTIQUE BASELINE AVEC TECHNIQUES AVANC√âES\n",
    "print(\"üéØ 3. PIPELINE R√âGRESSION LOGISTIQUE BASELINE AVEC TECHNIQUES AVANC√âES\")\n",
    "\n",
    "# Pipeline complet = MOD√àLE (am√©lior√© par GridSearchCV)\n",
    "# Note: Les donn√©es sont d√©j√† pr√©trait√©es (standardis√©es et encod√©es)\n",
    "logreg_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),                    # Standardisation\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Features non-lin√©aires\n",
    "    ('feature_selector', SequentialFeatureSelector(   # S√©lection automatique\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        n_features_to_select='auto',\n",
    "        direction='forward',\n",
    "        scoring='accuracy',\n",
    "        cv=3\n",
    "    )),\n",
    "    ('logreg', LogisticRegression(max_iter=1000, random_state=42))  # Mod√®le baseline\n",
    "])\n",
    "\n",
    "# GridSearchCV pour optimiser le pipeline\n",
    "param_grid_logreg = {\n",
    "    'poly__degree': [1, 2],\n",
    "    'feature_selector__n_features_to_select': [2, 3, 4],\n",
    "    'logreg__C': [0.01, 0.1, 1.0, 10.0],\n",
    "    'logreg__penalty': ['l1', 'l2'],\n",
    "    'logreg__solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "grid_search_logreg = GridSearchCV(\n",
    "    logreg_pipeline,\n",
    "    param_grid_logreg,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"üîç Recherche des meilleurs hyperparam√®tres...\")\n",
    "grid_search_logreg.fit(X_train, y_train)\n",
    "\n",
    "print(f\"üèÜ Meilleurs param√®tres R√©gression Logistique :\")\n",
    "for param, value in grid_search_logreg.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"üìä Meilleur score CV : {grid_search_logreg.best_score_:.4f}\")\n",
    "\n",
    "# Le pipeline optimis√© DEVIENT le mod√®le final\n",
    "logreg_model_final = grid_search_logreg.best_estimator_\n",
    "print(f\"‚úÖ Pipeline R√©gression Logistique optimis√© = Mod√®le final : {type(logreg_model_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. √âVALUATION DES 3 MOD√àLES BASELINE AVEC TECHNIQUES AVANC√âES\n",
    "print(\"4. √âVALUATION DES 3 MOD√àLES BASELINE AVEC TECHNIQUES AVANC√âES\")\n",
    "\n",
    "# √âvaluation KNN\n",
    "y_pred_knn = knn_model_final.predict(X_test)\n",
    "y_proba_knn = knn_model_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "roc_auc_knn = roc_auc_score(y_test, y_proba_knn)\n",
    "\n",
    "print(f\"\\nPerformance KNN sur test :\")\n",
    "print(f\"  Accuracy : {accuracy_knn:.4f}\")\n",
    "print(f\"  ROC AUC : {roc_auc_knn:.4f}\")\n",
    "\n",
    "# √âvaluation R√©gression Lin√©aire\n",
    "y_pred_linreg_proba = linreg_model_final.predict(X_test)\n",
    "y_pred_linreg = (y_pred_linreg_proba >= 0.5).astype(int)  # Seuillage pour classification\n",
    "\n",
    "accuracy_linreg = accuracy_score(y_test, y_pred_linreg)\n",
    "mse_linreg = np.mean((y_test - y_pred_linreg_proba) ** 2)\n",
    "roc_auc_linreg = roc_auc_score(y_test, y_pred_linreg_proba)\n",
    "\n",
    "print(f\"\\nPerformance R√©gression Lin√©aire sur test :\")\n",
    "print(f\"  Accuracy : {accuracy_linreg:.4f}\")\n",
    "print(f\"  MSE : {mse_linreg:.4f}\")\n",
    "print(f\"  ROC AUC : {roc_auc_linreg:.4f}\")\n",
    "\n",
    "# √âvaluation R√©gression Logistique\n",
    "y_pred_logreg = logreg_model_final.predict(X_test)\n",
    "y_proba_logreg = logreg_model_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "roc_auc_logreg = roc_auc_score(y_test, y_proba_logreg)\n",
    "\n",
    "print(f\"\\nPerformance R√©gression Logistique sur test :\")\n",
    "print(f\"  Accuracy : {accuracy_logreg:.4f}\")\n",
    "print(f\"  ROC AUC : {roc_auc_logreg:.4f}\")\n",
    "\n",
    "# Visualisation comparative des 3 mod√®les\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "models = ['KNN', 'R√©gression Lin√©aire', 'R√©gression Logistique']\n",
    "accuracies = [accuracy_knn, accuracy_linreg, accuracy_logreg]\n",
    "roc_aucs = [roc_auc_knn, roc_auc_linreg, roc_auc_logreg]\n",
    "\n",
    "# Accuracy Comparison\n",
    "axes[0].bar(models, accuracies, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
    "axes[0].set_title('Accuracy Test (3 Algorithmes)')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "for i, v in enumerate(accuracies):\n",
    "    axes[0].text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "\n",
    "# ROC AUC Comparison\n",
    "axes[1].bar(models, roc_aucs, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
    "axes[1].set_title('ROC AUC (3 Algorithmes)')\n",
    "axes[1].set_ylabel('ROC AUC')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "for i, v in enumerate(roc_aucs):\n",
    "    axes[1].text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "\n",
    "# CV vs Test\n",
    "cv_scores = [grid_search_knn.best_score_, -grid_search_linreg.best_score_, grid_search_logreg.best_score_]\n",
    "test_scores = [accuracy_knn, accuracy_linreg, accuracy_logreg]\n",
    "axes[2].scatter(cv_scores, test_scores, s=100, c=['skyblue', 'lightgreen', 'lightcoral'])\n",
    "axes[2].plot([0.8, 1], [0.8, 1], 'k--', alpha=0.5)\n",
    "axes[2].set_xlabel('Score CV')\n",
    "axes[2].set_ylabel('Score Test')\n",
    "axes[2].set_title('CV vs Test (3 Algorithmes)')\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    axes[2].annotate(model, (cv_scores[i], test_scores[i]), \n",
    "                    xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition de available_features pour la sauvegarde des mod√®les\n",
    "# C'est l'ensemble des features utilis√©es pour l'entra√Ænement (y compris Category)\n",
    "baseline_features = ['Quantity', 'UnitPrice', 'Discount', 'ShippingCost']\n",
    "category_feature = ['Category']\n",
    "available_features = baseline_features + category_feature\n",
    "print(f\"‚úÖ available_features d√©fini : {available_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. SAUVEGARDE DES 3 MOD√àLES BASELINE POUR STREAMLIT\n",
    "print(\"5. SAUVEGARDE DES 3 MOD√àLES BASELINE POUR STREAMLIT\")\n",
    "\n",
    "# 1. Sauvegarde du mod√®le KNN baseline\n",
    "knn_model_data = {\n",
    "    'pipeline': knn_model_final,                    # Pipeline = Mod√®le optimis√©\n",
    "    'model_name': 'KNN Baseline Avanc√©',\n",
    "    'model_type': 'KNN',\n",
    "    'baseline_features': available_features,\n",
    "    'best_params': grid_search_knn.best_params_,\n",
    "    'cv_score': grid_search_knn.best_score_,\n",
    "    'test_score': accuracy_knn,\n",
    "    'roc_auc': roc_auc_knn,\n",
    "    'techniques_used': {\n",
    "        'polynomial_features': True,\n",
    "        'sequential_feature_selector': True,\n",
    "        'cross_validation': True,\n",
    "        'grid_search_cv': True,\n",
    "        'pipeline_as_model': True\n",
    "    },\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'description': 'KNN baseline simple avec techniques avanc√©es (Pipeline = Mod√®le)'\n",
    "}\n",
    "\n",
    "joblib.dump(knn_model_data, '../models/knn_baseline_model.pkl')\n",
    "print(\"‚úÖ Mod√®le KNN baseline sauvegard√© : ../models/knn_baseline_model.pkl\")\n",
    "\n",
    "# 2. Sauvegarde du mod√®le R√©gression Lin√©aire baseline\n",
    "linreg_model_data = {\n",
    "    'pipeline': linreg_model_final,                # Pipeline = Mod√®le optimis√©\n",
    "    'model_name': 'R√©gression Lin√©aire Baseline Avanc√©',\n",
    "    'model_type': 'Linear Regression',\n",
    "    'baseline_features': available_features,\n",
    "    'best_params': grid_search_linreg.best_params_,\n",
    "    'cv_score': -grid_search_linreg.best_score_,\n",
    "    'test_score': accuracy_linreg,\n",
    "    'mse': mse_linreg,\n",
    "    'roc_auc': roc_auc_linreg,\n",
    "    'techniques_used': {\n",
    "        'polynomial_features': True,\n",
    "        'sequential_feature_selector': True,\n",
    "        'cross_validation': True,\n",
    "        'grid_search_cv': True,\n",
    "        'pipeline_as_model': True\n",
    "    },\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'description': 'R√©gression Lin√©aire baseline simple avec techniques avanc√©es (Pipeline = Mod√®le)'\n",
    "}\n",
    "\n",
    "joblib.dump(linreg_model_data, '../models/linreg_baseline_model.pkl')\n",
    "print(\"‚úÖ Mod√®le R√©gression Lin√©aire baseline sauvegard√© : ../models/linreg_baseline_model.pkl\")\n",
    "\n",
    "# 3. Sauvegarde du mod√®le R√©gression Logistique baseline\n",
    "logreg_model_data = {\n",
    "    'pipeline': logreg_model_final,                # Pipeline = Mod√®le optimis√©\n",
    "    'model_name': 'R√©gression Logistique Baseline Avanc√©',\n",
    "    'model_type': 'Logistic Regression',\n",
    "    'baseline_features': available_features,\n",
    "    'best_params': grid_search_logreg.best_params_,\n",
    "    'cv_score': grid_search_logreg.best_score_,\n",
    "    'test_score': accuracy_logreg,\n",
    "    'roc_auc': roc_auc_logreg,\n",
    "    'techniques_used': {\n",
    "        'polynomial_features': True,\n",
    "        'sequential_feature_selector': True,\n",
    "        'cross_validation': True,\n",
    "        'grid_search_cv': True,\n",
    "        'pipeline_as_model': True\n",
    "    },\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'description': 'R√©gression Logistique baseline simple avec techniques avanc√©es (Pipeline = Mod√®le)'\n",
    "}\n",
    "\n",
    "joblib.dump(logreg_model_data, '../models/logreg_baseline_model.pkl')\n",
    "print(\"‚úÖ Mod√®le R√©gression Logistique baseline sauvegard√© : ../models/logreg_baseline_model.pkl\")\n",
    "\n",
    "# 4. Cr√©ation d'un index des 3 mod√®les baseline pour Streamlit\n",
    "baseline_models_index = {\n",
    "    'baseline_models': {\n",
    "        'knn': {\n",
    "            'file': '../models/knn_baseline_model.pkl',\n",
    "            'name': 'KNN Baseline Avanc√©',\n",
    "            'description': 'KNN baseline simple avec techniques avanc√©es',\n",
    "            'accuracy': accuracy_knn,\n",
    "            'roc_auc': roc_auc_knn,\n",
    "            'features': available_features\n",
    "        },\n",
    "        'linreg': {\n",
    "            'file': '../models/linreg_baseline_model.pkl',\n",
    "            'name': 'R√©gression Lin√©aire Baseline Avanc√©',\n",
    "            'description': 'R√©gression Lin√©aire baseline simple avec techniques avanc√©es',\n",
    "            'accuracy': accuracy_linreg,\n",
    "            'roc_auc': roc_auc_linreg,\n",
    "            'features': available_features\n",
    "        },\n",
    "        'logreg': {\n",
    "            'file': '../models/logreg_baseline_model.pkl',\n",
    "            'name': 'R√©gression Logistique Baseline Avanc√©',\n",
    "            'description': 'R√©gression Logistique baseline simple avec techniques avanc√©es',\n",
    "            'accuracy': accuracy_logreg,\n",
    "            'roc_auc': roc_auc_logreg,\n",
    "            'features': available_features\n",
    "        }\n",
    "    },\n",
    "    'comparison': {\n",
    "        'best_accuracy_model': max(['knn', 'linreg', 'logreg'], key=lambda x: [accuracy_knn, accuracy_linreg, accuracy_logreg][['knn', 'linreg', 'logreg'].index(x)]),\n",
    "        'best_roc_auc_model': max(['knn', 'linreg', 'logreg'], key=lambda x: [roc_auc_knn, roc_auc_linreg, roc_auc_logreg][['knn', 'linreg', 'logreg'].index(x)]),\n",
    "        'algorithms_count': 3\n",
    "    },\n",
    "    'baseline_approach': {\n",
    "        'simple_features': True,\n",
    "        'advanced_techniques': True,\n",
    "        'pipeline_as_model': True,\n",
    "        'tp_cpu_load_style': True,\n",
    "        'three_algorithms': True\n",
    "    },\n",
    "    'techniques_applied': [\n",
    "        'PolynomialFeatures (degree 1-2)',\n",
    "        'SequentialFeatureSelector (forward)',\n",
    "        'StratifiedKFold CrossValidation',\n",
    "        'GridSearchCV (optimisation pipeline)',\n",
    "        'Pipeline (devient le mod√®le)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "joblib.dump(baseline_models_index, '../models/baseline_models_index.pkl')\n",
    "print(\"‚úÖ Index des 3 mod√®les baseline sauvegard√© : ../models/baseline_models_index.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. COMPARAISON FINALE DES 3 ALGORITHMES\n",
    "print(\"üèÜ 6. COMPARAISON FINALE DES 3 ALGORITHMES\")\n",
    "\n",
    "# Tableau comparatif final des 3 mod√®les\n",
    "comparison_results = pd.DataFrame({\n",
    "    'Mod√®le': ['KNN Baseline Avanc√©', 'R√©gression Lin√©aire Baseline Avanc√©', 'R√©gression Logistique Baseline Avanc√©'],\n",
    "    'Type': ['KNN', 'Linear Regression', 'Logistic Regression'],\n",
    "    'Score CV': [grid_search_knn.best_score_, -grid_search_linreg.best_score_, grid_search_logreg.best_score_],\n",
    "    'Accuracy Test': [accuracy_knn, accuracy_linreg, accuracy_logreg],\n",
    "    'ROC AUC': [roc_auc_knn, roc_auc_linreg, roc_auc_logreg],\n",
    "    'Polynomial Features': ['Oui', 'Oui', 'Oui'],\n",
    "    'Feature Selector': ['Oui', 'Oui', 'Oui'],\n",
    "    'Pipeline = Mod√®le': ['Oui', 'Oui', 'Oui']\n",
    "})\n",
    "\n",
    "print(\"\\nüìä TABLEAU COMPARATIF FINAL (3 Algorithmes) :\")\n",
    "print(comparison_results.round(4))\n",
    "\n",
    "# D√©termination du vainqueur\n",
    "best_accuracy_idx = comparison_results['Accuracy Test'].idxmax()\n",
    "best_roc_auc_idx = comparison_results['ROC AUC'].idxmax()\n",
    "\n",
    "best_accuracy_model = comparison_results.iloc[best_accuracy_idx]\n",
    "best_roc_auc_model = comparison_results.iloc[best_roc_auc_idx]\n",
    "\n",
    "print(f\"\\nü•á VAINQUEUR PAR ACCURACY : {best_accuracy_model['Mod√®le']}\")\n",
    "print(f\"   Accuracy : {best_accuracy_model['Accuracy Test']:.4f}\")\n",
    "print(f\"   ROC AUC : {best_accuracy_model['ROC AUC']:.4f}\")\n",
    "\n",
    "print(f\"\\nü•á VAINQUEUR PAR ROC AUC : {best_roc_auc_model['Mod√®le']}\")\n",
    "print(f\"   Accuracy : {best_roc_auc_model['Accuracy Test']:.4f}\")\n",
    "print(f\"   ROC AUC : {best_roc_auc_model['ROC AUC']:.4f}\")\n",
    "\n",
    "# Vainqueur global (score composite)\n",
    "def composite_score(row):\n",
    "    return 0.6 * row['Accuracy Test'] + 0.4 * row['ROC AUC']\n",
    "\n",
    "comparison_results['Score Composite'] = comparison_results.apply(composite_score, axis=1)\n",
    "best_global_idx = comparison_results['Score Composite'].idxmax()\n",
    "best_global_model = comparison_results.iloc[best_global_idx]\n",
    "\n",
    "print(f\"\\nüèÜ VAINQUEUR GLOBAL (Score Composite) : {best_global_model['Mod√®le']}\")\n",
    "print(f\"   Score Composite : {best_global_model['Score Composite']:.4f}\")\n",
    "print(f\"   Accuracy : {best_global_model['Accuracy Test']:.4f}\")\n",
    "print(f\"   ROC AUC : {best_global_model['ROC AUC']:.4f}\")\n",
    "\n",
    "# Sauvegarde du meilleur mod√®le baseline\n",
    "if best_global_model['Mod√®le'] == 'KNN Baseline Avanc√©':\n",
    "    joblib.dump(knn_model_data, '../models/best_baseline_model.pkl')\n",
    "    print(f\"\\n‚úÖ Meilleur mod√®le baseline sauvegard√© : ../models/best_baseline_model.pkl (KNN)\")\n",
    "elif best_global_model['Mod√®le'] == 'R√©gression Lin√©aire Baseline Avanc√©':\n",
    "    joblib.dump(linreg_model_data, '../models/best_baseline_model.pkl')\n",
    "    print(f\"\\n‚úÖ Meilleur mod√®le baseline sauvegard√© : ../models/best_baseline_model.pkl (R√©gression Lin√©aire)\")\n",
    "else:\n",
    "    joblib.dump(logreg_model_data, '../models/best_baseline_model.pkl')\n",
    "    print(f\"\\n‚úÖ Meilleur mod√®le baseline sauvegard√© : ../models/best_baseline_model.pkl (R√©gression Logistique)\")\n",
    "\n",
    "print(f\"\\nüéØ EXIGENCE CAHIER DES CHARGES RESPECT√âE : 3+ algorithmes utilis√©s !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. TEST PRATIQUE DES 3 PIPELINES\n",
    "print(\"üß™ 7. TEST PRATIQUE DES 3 PIPELINES\")\n",
    "\n",
    "# Exemple de transaction test\n",
    "test_transaction = pd.DataFrame({\n",
    "    'Quantity': [2],\n",
    "    'UnitPrice': [50.0],\n",
    "    'Discount': [0.1],\n",
    "    'ShippingCost': [5.0]\n",
    "})\n",
    "\n",
    "print(\"üí° Transaction test :\")\n",
    "print(test_transaction.T)\n",
    "\n",
    "# Pr√©dictions avec les 3 pipelines (mod√®les)\n",
    "print(f\"\\nüîÆ PR√âDICTIONS AVEC LES 3 PIPELINES = MOD√àLES :\")\n",
    "\n",
    "# KNN Pipeline\n",
    "knn_pred = knn_model_final.predict(test_transaction)[0]\n",
    "knn_proba = knn_model_final.predict_proba(test_transaction)[0][1]\n",
    "print(f\"KNN Pipeline : {'RETOUR' if knn_pred == 1 else 'PAS DE RETOUR'} ({knn_proba:.3f})\")\n",
    "\n",
    "# R√©gression Lin√©aire Pipeline\n",
    "linreg_pred_proba = linreg_model_final.predict(test_transaction)[0]\n",
    "linreg_pred = 1 if linreg_pred_proba >= 0.5 else 0\n",
    "print(f\"R√©gression Lin√©aire Pipeline : {'RETOUR' if linreg_pred == 1 else 'PAS DE RETOUR'} ({linreg_pred_proba:.3f})\")\n",
    "\n",
    "# R√©gression Logistique Pipeline\n",
    "logreg_pred = logreg_model_final.predict(test_transaction)[0]\n",
    "logreg_proba = logreg_model_final.predict_proba(test_transaction)[0][1]\n",
    "print(f\"R√©gression Logistique Pipeline : {'RETOUR' if logreg_pred == 1 else 'PAS DE RETOUR'} ({logreg_proba:.3f})\")\n",
    "\n",
    "# Analyse des pipelines\n",
    "print(f\"\\nüîß ANALYSE DES 3 PIPELINES :\")\n",
    "\n",
    "print(f\"\\nüìã Pipeline KNN ({len(knn_model_final.named_steps)} √©tapes) :\")\n",
    "for i, (name, step) in enumerate(knn_model_final.named_steps.items()):\n",
    "    print(f\"  {i+1}. {name}: {type(step).__name__}\")\n",
    "\n",
    "print(f\"\\nüìã Pipeline R√©gression Lin√©aire ({len(linreg_model_final.named_steps)} √©tapes) :\")\n",
    "for i, (name, step) in enumerate(linreg_model_final.named_steps.items()):\n",
    "    print(f\"  {i+1}. {name}: {type(step).__name__}\")\n",
    "\n",
    "print(f\"\\nüìã Pipeline R√©gression Logistique ({len(logreg_model_final.named_steps)} √©tapes) :\")\n",
    "for i, (name, step) in enumerate(logreg_model_final.named_steps.items()):\n",
    "    print(f\"  {i+1}. {name}: {type(step).__name__}\")\n",
    "\n",
    "print(f\"\\n‚úÖ 3 algorithmes avec pipelines complets pr√™ts pour Streamlit !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Resultats\n",
    "\n",
    "print(f\"\\nCOMPARAISON DES 3 ALGORITHMES :\")\n",
    "print(f\"   ‚úÖ KNN Accuracy : {accuracy_knn:.4f}\")\n",
    "print(f\"   ‚úÖ KNN ROC AUC : {roc_auc_knn:.4f}\")\n",
    "print(f\"   ‚úÖ R√©gression Lin√©aire Accuracy : {accuracy_linreg:.4f}\")\n",
    "print(f\"   ‚úÖ R√©gression Lin√©aire ROC AUC : {roc_auc_linreg:.4f}\")\n",
    "print(f\"   ‚úÖ R√©gression Logistique Accuracy : {accuracy_logreg:.4f}\")\n",
    "print(f\"   ‚úÖ R√©gression Logistique ROC AUC : {roc_auc_logreg:.4f}\")\n",
    "\n",
    "print(f\"\\nSAUVEGARDE DE CHAQUE MOD√àLE :\")\n",
    "print(f\"   ‚úÖ KNN : ../models/knn_baseline_model.pkl\")\n",
    "print(f\"   ‚úÖ R√©gression Lin√©aire : ../models/linreg_baseline_model.pkl\")\n",
    "print(f\"   ‚úÖ R√©gression Logistique : ../models/logreg_baseline_model.pkl\")\n",
    "print(f\"   ‚úÖ Meilleur mod√®le : ../models/best_baseline_model.pkl\")\n",
    "print(f\"   ‚úÖ Index : ../models/baseline_models_index.pkl\")\n",
    "\n",
    "print(f\"\\nR√âSULTATS FINAUX :\")\n",
    "print(f\"   ü•á Meilleur mod√®le : {best_global_model['Mod√®le']}\")\n",
    "print(f\"   üìä Score Composite : {best_global_model['Score Composite']:.4f}\")\n",
    "print(f\"   üéØ Accuracy : {best_global_model['Accuracy Test']:.4f}\")\n",
    "print(f\"   üìà ROC AUC : {best_global_model['ROC AUC']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Visualisations finales\n",
    "print(\"üìä 8. Visualisations finales:\")\n",
    "\n",
    "# Utiliser les pr√©dictions du meilleur mod√®le (R√©gression Lin√©aire selon les r√©sultats)\n",
    "best_model_name = \"R√©gression Lin√©aire Baseline Avanc√©\"\n",
    "y_test_pred = y_pred_linreg  # Utiliser les pr√©dictions d√©j√† calcul√©es\n",
    "y_test_proba = y_pred_linreg_proba  # Utiliser les probabilit√©s d√©j√† calcul√©es\n",
    "\n",
    "# Matrice de confusion\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Non Retour', 'Retour'],\n",
    "            yticklabels=['Non Retour', 'Retour'])\n",
    "plt.title(f'Matrice de Confusion - {best_model_name}')\n",
    "plt.ylabel('Vrai')\n",
    "plt.xlabel('Pr√©dit')\n",
    "plt.show()\n",
    "\n",
    "# Courbe ROC\n",
    "from sklearn.metrics import roc_curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, \n",
    "         label=f'ROC curve (AUC = {roc_auc_linreg:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux de Faux Positifs')\n",
    "plt.ylabel('Taux de Vrais Positifs')\n",
    "plt.title(f'Courbe ROC - {best_model_name}')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Distribution des probabilit√©s\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(y_test_proba[y_test == 0], bins=30, alpha=0.7, label='Non Retour', density=True)\n",
    "plt.hist(y_test_proba[y_test == 1], bins=30, alpha=0.7, label='Retour', density=True)\n",
    "plt.xlabel('Probabilit√© pr√©dite')\n",
    "plt.ylabel('Densit√©')\n",
    "plt.title(f'Distribution des Probabilit√©s - {best_model_name}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Analyse des performances par seuil\n",
    "print(\"üéØ 9. Analyse des performances par seuil:\")\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Analyse de diff√©rentes m√©triques pour diff√©rents seuils\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "threshold_metrics = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = (y_test_proba >= threshold).astype(int)\n",
    "    \n",
    "    metrics = {\n",
    "        'threshold': threshold,\n",
    "        'accuracy': accuracy_score(y_test, y_pred_threshold),\n",
    "        'precision': precision_score(y_test, y_pred_threshold, zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred_threshold, zero_division=0),\n",
    "        'f1_score': f1_score(y_test, y_pred_threshold, zero_division=0)\n",
    "    }\n",
    "    threshold_metrics.append(metrics)\n",
    "\n",
    "threshold_df = pd.DataFrame(threshold_metrics)\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Accuracy\n",
    "axes[0,0].plot(threshold_df['threshold'], threshold_df['accuracy'], 'b-o')\n",
    "axes[0,0].set_title('Accuracy par seuil')\n",
    "axes[0,0].set_xlabel('Seuil')\n",
    "axes[0,0].set_ylabel('Accuracy')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision\n",
    "axes[0,1].plot(threshold_df['threshold'], threshold_df['precision'], 'r-o')\n",
    "axes[0,1].set_title('Precision par seuil')\n",
    "axes[0,1].set_xlabel('Seuil')\n",
    "axes[0,1].set_ylabel('Precision')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Recall\n",
    "axes[1,0].plot(threshold_df['threshold'], threshold_df['recall'], 'g-o')\n",
    "axes[1,0].set_title('Recall par seuil')\n",
    "axes[1,0].set_xlabel('Seuil')\n",
    "axes[1,0].set_ylabel('Recall')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# F1-Score\n",
    "axes[1,1].plot(threshold_df['threshold'], threshold_df['f1_score'], 'm-o')\n",
    "axes[1,1].set_title('F1-Score par seuil')\n",
    "axes[1,1].set_xlabel('Seuil')\n",
    "axes[1,1].set_ylabel('F1-Score')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Meilleur seuil pour F1-Score\n",
    "best_threshold_idx = threshold_df['f1_score'].idxmax()\n",
    "best_threshold = threshold_df.loc[best_threshold_idx, 'threshold']\n",
    "best_f1 = threshold_df.loc[best_threshold_idx, 'f1_score']\n",
    "\n",
    "print(f\"\\nüéØ Meilleur seuil pour F1-Score: {best_threshold:.2f}\")\n",
    "print(f\"üìä F1-Score √† ce seuil: {best_f1:.4f}\")\n",
    "print(f\"üìã M√©triques au seuil optimal:\")\n",
    "print(f\"   Accuracy: {threshold_df.loc[best_threshold_idx, 'accuracy']:.4f}\")\n",
    "print(f\"   Precision: {threshold_df.loc[best_threshold_idx, 'precision']:.4f}\")\n",
    "print(f\"   Recall: {threshold_df.loc[best_threshold_idx, 'recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Sauvegarde de TOUS les mod√®les pour Streamlit\n",
    "print(\"üíæ 10. Sauvegarde de tous les mod√®les pour l'application Streamlit:\")\n",
    "\n",
    "# 1. Sauvegarde du mod√®le KNN complet (d√©j√† fait mais on v√©rifie)\n",
    "knn_complete_data = {\n",
    "    'pipeline': knn_model_final,\n",
    "    'model_name': 'KNN Baseline Avanc√©',\n",
    "    'model_type': 'Pipeline',\n",
    "    'feature_names': available_features,\n",
    "    'test_metrics': {\n",
    "        'accuracy': accuracy_knn,\n",
    "        'roc_auc': roc_auc_knn\n",
    "    },\n",
    "    'best_params': grid_search_knn.best_params_,\n",
    "    'cv_score': grid_search_knn.best_score_,\n",
    "    'description': 'KNN baseline avec techniques avanc√©es (Pipeline = Mod√®le)',\n",
    "    'techniques_used': ['PolynomialFeatures', 'SequentialFeatureSelector', 'GridSearchCV', 'Pipeline']\n",
    "}\n",
    "joblib.dump(knn_complete_data, '../models/knn_complete_model.pkl')\n",
    "print(\"‚úÖ Mod√®le KNN complet sauvegard√©: '../models/knn_complete_model.pkl'\")\n",
    "\n",
    "# 2. Sauvegarde du mod√®le R√©gression Lin√©aire complet (d√©j√† fait mais on v√©rifie)\n",
    "linreg_complete_data = {\n",
    "    'pipeline': linreg_model_final,\n",
    "    'model_name': 'R√©gression Lin√©aire Baseline Avanc√©',\n",
    "    'model_type': 'Pipeline',\n",
    "    'feature_names': available_features,\n",
    "    'test_metrics': {\n",
    "        'accuracy': accuracy_linreg,\n",
    "        'roc_auc': roc_auc_linreg,\n",
    "        'mse': mse_linreg\n",
    "    },\n",
    "    'best_params': grid_search_linreg.best_params_,\n",
    "    'cv_score': -grid_search_linreg.best_score_,\n",
    "    'description': 'R√©gression Lin√©aire baseline avec techniques avanc√©es (Pipeline = Mod√®le)',\n",
    "    'techniques_used': ['PolynomialFeatures', 'SequentialFeatureSelector', 'GridSearchCV', 'Pipeline']\n",
    "}\n",
    "joblib.dump(linreg_complete_data, '../models/linreg_complete_model.pkl')\n",
    "print(\"‚úÖ Mod√®le R√©gression Lin√©aire complet sauvegard√©: '../models/linreg_complete_model.pkl'\")\n",
    "\n",
    "# 3. Sauvegarde du meilleur mod√®le avec m√©tadonn√©es compl√®tes\n",
    "best_complete_data = {\n",
    "    'pipeline': best_global_model['Mod√®le'] == 'KNN Baseline Avanc√©' and knn_model_final or linreg_model_final,\n",
    "    'model_name': best_global_model['Mod√®le'],\n",
    "    'model_type': 'Pipeline',\n",
    "    'feature_names': available_features,\n",
    "    'final_metrics': {\n",
    "        'accuracy': best_global_model['Accuracy Test'],\n",
    "        'roc_auc': best_global_model['ROC AUC'],\n",
    "        'composite_score': best_global_model['Score Composite']\n",
    "    },\n",
    "    'best_params': best_global_model['Mod√®le'] == 'KNN Baseline Avanc√©' and grid_search_knn.best_params_ or grid_search_linreg.best_params_,\n",
    "    'cv_score': best_global_model['Mod√®le'] == 'KNN Baseline Avanc√©' and grid_search_knn.best_score_ or -grid_search_linreg.best_score_,\n",
    "    'threshold_analysis': threshold_df.to_dict() if 'threshold_df' in locals() else None,\n",
    "    'best_threshold': best_threshold if 'best_threshold' in locals() else 0.5,\n",
    "    'comparison_results': comparison_results.to_dict(),\n",
    "    'description': f'Meilleur mod√®le baseline: {best_global_model[\"Mod√®le\"]}',\n",
    "    'selection_criteria': 'Score composite (60% Accuracy + 40% ROC AUC)',\n",
    "    'techniques_used': ['PolynomialFeatures', 'SequentialFeatureSelector', 'GridSearchCV', 'Pipeline']\n",
    "}\n",
    "joblib.dump(best_complete_data, '../models/best_complete_model.pkl')\n",
    "print(f\"‚úÖ Meilleur mod√®le sauvegard√©: '../models/best_complete_model.pkl' ({best_global_model['Mod√®le']})\")\n",
    "\n",
    "# 4. Cr√©ation d'un index des mod√®les pour Streamlit\n",
    "complete_models_index = {\n",
    "    'available_models': {\n",
    "        'knn': {\n",
    "            'file': '../models/knn_complete_model.pkl',\n",
    "            'name': 'KNN Baseline Avanc√©',\n",
    "            'description': 'KNN baseline avec techniques avanc√©es',\n",
    "            'accuracy': accuracy_knn,\n",
    "            'roc_auc': roc_auc_knn,\n",
    "            'cv_score': grid_search_knn.best_score_\n",
    "        },\n",
    "        'linreg': {\n",
    "            'file': '../models/linreg_complete_model.pkl',\n",
    "            'name': 'R√©gression Lin√©aire Baseline Avanc√©',\n",
    "            'description': 'R√©gression Lin√©aire baseline avec techniques avanc√©es',\n",
    "            'accuracy': accuracy_linreg,\n",
    "            'roc_auc': roc_auc_linreg,\n",
    "            'cv_score': -grid_search_linreg.best_score_\n",
    "        },\n",
    "        'best': {\n",
    "            'file': '../models/best_complete_model.pkl',\n",
    "            'name': best_global_model['Mod√®le'],\n",
    "            'description': f'Meilleur mod√®le baseline: {best_global_model[\"Mod√®le\"]}',\n",
    "            'accuracy': best_global_model['Accuracy Test'],\n",
    "            'roc_auc': best_global_model['ROC AUC'],\n",
    "            'composite_score': best_global_model['Score Composite']\n",
    "        }\n",
    "    },\n",
    "    'best_model_key': 'best',\n",
    "    'feature_names': available_features,\n",
    "    'data_info': {\n",
    "        'n_features': len(available_features),\n",
    "        'target_classes': ['Non Retour', 'Retour'],\n",
    "        'baseline_approach': True,\n",
    "        'preprocessing': {\n",
    "            'scaler': 'StandardScaler',\n",
    "            'polynomial_features': True,\n",
    "            'max_degree': 2,\n",
    "            'feature_selector': 'SequentialFeatureSelector'\n",
    "        }\n",
    "    },\n",
    "    'evaluation_metrics': {\n",
    "        'best_accuracy': best_global_model['Accuracy Test'],\n",
    "        'best_roc_auc': best_global_model['ROC AUC'],\n",
    "        'best_composite_score': best_global_model['Score Composite']\n",
    "    },\n",
    "    'techniques_applied': [\n",
    "        'PolynomialFeatures (degree 1-2)',\n",
    "        'SequentialFeatureSelector (forward)',\n",
    "        'StratifiedKFold CrossValidation',\n",
    "        'GridSearchCV (optimisation pipeline)',\n",
    "        'Pipeline (devient le mod√®le)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "joblib.dump(complete_models_index, '../models/complete_models_index.pkl')\n",
    "print(\"‚úÖ Index complet des mod√®les sauvegard√©: '../models/complete_models_index.pkl'\")\n",
    "\n",
    "# 5. R√©sum√© des sauvegardes\n",
    "print(f\"\\nüìä R√©sum√© des mod√®les sauvegard√©s:\")\n",
    "print(f\"ü§ñ KNN: Accuracy = {accuracy_knn:.4f}, ROC AUC = {roc_auc_knn:.4f}\")\n",
    "print(f\"üìà R√©gression Lin√©aire: Accuracy = {accuracy_linreg:.4f}, ROC AUC = {roc_auc_linreg:.4f}\")\n",
    "print(f\"üèÜ Meilleur mod√®le ({best_global_model['Mod√®le']}): Accuracy = {best_global_model['Accuracy Test']:.4f}, ROC AUC = {best_global_model['ROC AUC']:.4f}\")\n",
    "\n",
    "print(f\"\\nüîß Structure du pipeline final:\")\n",
    "best_pipeline = best_global_model['Mod√®le'] == 'KNN Baseline Avanc√©' and knn_model_final or linreg_model_final\n",
    "for i, (name, step) in enumerate(best_pipeline.named_steps.items()):\n",
    "    print(f\"  {i+1}. {name}: {type(step).__name__}\")\n",
    "\n",
    "print(f\"\\nüìÇ Fichiers cr√©√©s dans '../models/':\")\n",
    "print(f\"  - knn_complete_model.pkl (Mod√®le KNN complet)\")\n",
    "print(f\"  - linreg_complete_model.pkl (Mod√®le R√©gression Lin√©aire complet)\")\n",
    "print(f\"  - best_complete_model.pkl (Meilleur mod√®le complet)\")\n",
    "print(f\"  - complete_models_index.pkl (Index complet pour Streamlit)\")\n",
    "\n",
    "print(f\"\\nüéØ Utilisation dans Streamlit:\")\n",
    "print(f\"  - Charger l'index: models_index = joblib.load('models/complete_models_index.pkl')\")\n",
    "print(f\"  - Choisir un mod√®le: model_key = 'best' ou 'knn' ou 'linreg'\")\n",
    "print(f\"  - Charger le mod√®le: model_data = joblib.load(models_index['available_models'][model_key]['file'])\")\n",
    "print(f\"  - Pr√©dire: prediction = model_data['pipeline'].predict(X_new)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã R√©sum√© de la Mod√©lisation Avanc√©e\n",
    "\n",
    "### ‚úÖ Techniques Avanc√©es Impl√©ment√©es\n",
    "\n",
    "1. **Pipeline Complet**\n",
    "   - Int√©gration pr√©traitement ‚Üí feature engineering ‚Üí s√©lection ‚Üí mod√©lisation\n",
    "   - Reproductibilit√© garantie\n",
    "   - Optimisation globale des hyperparam√®tres\n",
    "\n",
    "2. **PolynomialFeatures**\n",
    "   - G√©n√©ration de features non-lin√©aires (degr√© 1-3)\n",
    "   - Capture des interactions entre variables\n",
    "   - Am√©lioration de la capacit√© de mod√©lisation\n",
    "\n",
    "3. **SequentialFeatureSelector**\n",
    "   - S√©lection automatique des features les plus pertinentes\n",
    "   - R√©duction de la dimensionalit√©\n",
    "   - Am√©lioration de la g√©n√©ralisation\n",
    "\n",
    "4. **CrossValidation Avanc√©e**\n",
    "   - StratifiedKFold pour pr√©server les proportions\n",
    "   - Validation sur 10 folds\n",
    "   - Analyse de la stabilit√© des performances\n",
    "\n",
    "5. **GridSearchCV sur Pipeline**\n",
    "   - Optimisation simultan√©e de tous les hyperparam√®tres\n",
    "   - Recherche exhaustive des meilleures combinaisons\n",
    "   - Validation crois√©e int√©gr√©e\n",
    "\n",
    "### üèÜ Mod√®les Compar√©s\n",
    "\n",
    "**KNN (K-Nearest Neighbors)**\n",
    "- Avantages: Non-param√©trique, adaptable aux formes complexes\n",
    "- Optimisation: n_neighbors, weights, metric, degree polynomial\n",
    "\n",
    "**R√©gression Logistique**\n",
    "- Avantages: Interpr√©table, rapide, probabiliste\n",
    "- Optimisation: C, penalty, solver, degree polynomial\n",
    "\n",
    "### üìä M√©triques d'√âvaluation\n",
    "\n",
    "- **Accuracy**: Pr√©dictions correctes / Total\n",
    "- **Precision**: Vrais positifs / (Vrais + Faux positifs)\n",
    "- **Recall**: Vrais positifs / (Vrais positifs + Faux n√©gatifs)\n",
    "- **F1-Score**: Moyenne harmonique de precision et recall\n",
    "- **ROC AUC**: Capacit√© de discrimination du mod√®le\n",
    "\n",
    "### üéØ S√©lection du Mod√®le Final\n",
    "\n",
    "**Crit√®re composite**: ROC AUC validation - p√©nalit√© overfitting\n",
    "- Poids 70% pour la performance (ROC AUC)\n",
    "- Poids 30% pour la stabilit√© (overfitting minimal)\n",
    "\n",
    "### üîç Analyses Compl√©mentaires\n",
    "\n",
    "1. **Analyse par seuil**: Optimisation du point de d√©cision\n",
    "2. **Distribution des probabilit√©s**: Compr√©hension des pr√©dictions\n",
    "3. **Stabilit√© par validation crois√©e**: Robustesse du mod√®le\n",
    "4. **Comparaison validation/test**: D√©tection de surapprentissage\n",
    "\n",
    "### üíæ Sauvegarde Compl√®te pour Streamlit\n",
    "\n",
    "**Fichiers cr√©√©s dans `../models/`:**\n",
    "- `knn_model.pkl` - Mod√®le KNN complet avec m√©tadonn√©es\n",
    "- `logreg_model.pkl` - Mod√®le R√©gression Logistique complet avec m√©tadonn√©es  \n",
    "- `best_model.pkl` - Meilleur mod√®le s√©lectionn√© avec analyses compl√®tes\n",
    "- `models_index.pkl` - Index des mod√®les pour navigation Streamlit\n",
    "- `model_utils.py` - Classe utilitaire pour Streamlit\n",
    "\n",
    "**Structure des mod√®les sauvegard√©s:**\n",
    "```python\n",
    "{\n",
    "    'pipeline': Pipeline complet,\n",
    "    'model_name': 'Nom du mod√®le',\n",
    "    'feature_names': ['feature1', 'feature2', ...],\n",
    "    'validation_metrics': {...},\n",
    "    'best_params': {...},\n",
    "    'scaler': scaler_obj,\n",
    "    'label_encoders': encoders_dict,\n",
    "    'description': 'Description du mod√®le'\n",
    "}\n",
    "```\n",
    "\n",
    "### üöÄ Int√©gration Streamlit\n",
    "\n",
    "**Utilisation simple:**\n",
    "```python\n",
    "from model_utils import ModelManager\n",
    "\n",
    "# Initialisation\n",
    "model_manager = ModelManager()\n",
    "\n",
    "# Charger le meilleur mod√®le\n",
    "model_manager.get_best_model()\n",
    "\n",
    "# Faire une pr√©diction\n",
    "result = model_manager.predict(X_new)\n",
    "print(f\"Pr√©diction: {result['prediction']}\")\n",
    "print(f\"Probabilit√©: {result['probability']}\")\n",
    "```\n",
    "\n",
    "**S√©lection dynamique des mod√®les:**\n",
    "- KNN pour les pr√©dictions non-lin√©aires\n",
    "- R√©gression Logistique pour les pr√©dictions interpr√©tables\n",
    "- Meilleur mod√®le pour les performances optimales\n",
    "\n",
    "---\n",
    "\n",
    "**‚úÖ Mod√©lisation avanc√©e termin√©e - Pipeline optimis√© pr√™t pour Streamlit**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
